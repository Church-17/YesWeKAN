{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocess_dataset as ut\n",
    "from scipy.interpolate import BSpline\n",
    "from tfkan import DenseKAN\n",
    "from tensorflow import keras\n",
    "from keras_tuner import HyperModel, GridSearch, RandomSearch\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 26) (15000, 26) (20000, 26) (60000, 1) (20000, 1) (15000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.convert_to_tensor(pd.read_csv(\"datasets/x_train.csv\").to_numpy()[:, 1:])\n",
    "y_train = tf.convert_to_tensor(pd.read_csv(\"datasets/y_train.csv\").to_numpy()[:, 1:])\n",
    "\n",
    "x_val = tf.convert_to_tensor(pd.read_csv(\"datasets/x_val.csv\").to_numpy()[:, 1:])\n",
    "y_val = tf.convert_to_tensor(pd.read_csv(\"datasets/y_val.csv\").to_numpy()[:, 1:])\n",
    "\n",
    "x_test = tf.convert_to_tensor(pd.read_csv(\"datasets/x_test.csv\").to_numpy()[:, 1:])\n",
    "y_test = tf.convert_to_tensor(pd.read_csv(\"datasets/y_test.csv\").to_numpy()[:, 1:])\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kan_layers = [4,1]\n",
    "#kan_model = ut.build_model(kan_layers, x_train.shape[1], mlp=False)\n",
    "#kan_model.summary()\n",
    "#\n",
    "#mlp_layers = [20,3,1]\n",
    "#mlp_model = ut.build_model(mlp_layers, x_train.shape[1], mlp=True)\n",
    "#mlp_model.summary()\n",
    "#kan_history = kan_model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_val, y_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Pura\n",
    "#\n",
    "#pure_mlp_layers = [64, 32, 16, 1]\n",
    "#mlp_model = ut.build_model(pure_mlp_layers, x_train.shape[1], mlp=True, optimizer='rmsprop', loss=\"categorical_crossentropy\")\n",
    "#mlp_model.summary()\n",
    "#\n",
    "#mlp_history = mlp_model.fit(x_train, y_train, epochs=50, batch_size=128, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 11m 02s]\n",
      "val_loss: 2.200371026992798\n",
      "\n",
      "Best val_loss So Far: 0.018934112042188644\n",
      "Total elapsed time: 06h 43m 48s\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Results summary\n",
      "Results in .\\modelli_salvati\\retina_kan\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 8\n",
      "grid_size_0: 3\n",
      "spline_order_0: 3\n",
      "units_1: 21\n",
      "grid_size_1: 4\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0050089061837515795\n",
      "optimizer: adam\n",
      "units_2: 32\n",
      "grid_size_2: 7\n",
      "spline_order_2: 2\n",
      "units_3: 8\n",
      "grid_size_3: 6\n",
      "spline_order_3: 2\n",
      "units_4: 11\n",
      "grid_size_4: 5\n",
      "spline_order_4: 2\n",
      "Score: 0.018934112042188644\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 22\n",
      "grid_size_0: 5\n",
      "spline_order_0: 2\n",
      "units_1: 5\n",
      "grid_size_1: 4\n",
      "spline_order_1: 3\n",
      "learning_rate: 0.0003082442963419899\n",
      "optimizer: adam\n",
      "units_2: 24\n",
      "grid_size_2: 5\n",
      "spline_order_2: 3\n",
      "units_3: 27\n",
      "grid_size_3: 7\n",
      "spline_order_3: 4\n",
      "units_4: 13\n",
      "grid_size_4: 7\n",
      "spline_order_4: 2\n",
      "Score: 0.023273497819900513\n",
      "\n",
      "Trial 42 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 4\n",
      "grid_size_0: 3\n",
      "spline_order_0: 4\n",
      "units_1: 23\n",
      "grid_size_1: 5\n",
      "spline_order_1: 3\n",
      "learning_rate: 0.0015324287478969592\n",
      "optimizer: adam\n",
      "units_2: 26\n",
      "grid_size_2: 4\n",
      "spline_order_2: 4\n",
      "units_3: 14\n",
      "grid_size_3: 4\n",
      "spline_order_3: 2\n",
      "units_4: 16\n",
      "grid_size_4: 3\n",
      "spline_order_4: 4\n",
      "Score: 0.02360682375729084\n",
      "\n",
      "Trial 36 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 22\n",
      "grid_size_0: 4\n",
      "spline_order_0: 4\n",
      "units_1: 23\n",
      "grid_size_1: 3\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0019505034249811953\n",
      "optimizer: adam\n",
      "units_2: 8\n",
      "grid_size_2: 7\n",
      "spline_order_2: 3\n",
      "units_3: 15\n",
      "grid_size_3: 7\n",
      "spline_order_3: 2\n",
      "units_4: 21\n",
      "grid_size_4: 5\n",
      "spline_order_4: 2\n",
      "Score: 0.026496632024645805\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 26\n",
      "grid_size_0: 6\n",
      "spline_order_0: 3\n",
      "units_1: 8\n",
      "grid_size_1: 7\n",
      "spline_order_1: 2\n",
      "learning_rate: 0.0014487708708113137\n",
      "optimizer: adam\n",
      "units_2: 8\n",
      "grid_size_2: 7\n",
      "spline_order_2: 2\n",
      "units_3: 23\n",
      "grid_size_3: 4\n",
      "spline_order_3: 4\n",
      "units_4: 16\n",
      "grid_size_4: 3\n",
      "spline_order_4: 2\n",
      "Score: 0.03756432980298996\n",
      "\n",
      "Trial 34 summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 6\n",
      "grid_size_0: 6\n",
      "spline_order_0: 4\n",
      "units_1: 17\n",
      "grid_size_1: 6\n",
      "spline_order_1: 2\n",
      "learning_rate: 0.0004059999358516054\n",
      "optimizer: adam\n",
      "units_2: 16\n",
      "grid_size_2: 5\n",
      "spline_order_2: 3\n",
      "units_3: 12\n",
      "grid_size_3: 7\n",
      "spline_order_3: 3\n",
      "units_4: 5\n",
      "grid_size_4: 5\n",
      "spline_order_4: 3\n",
      "Score: 0.03932736814022064\n",
      "\n",
      "Trial 31 summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 9\n",
      "grid_size_0: 7\n",
      "spline_order_0: 4\n",
      "units_1: 3\n",
      "grid_size_1: 3\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.00010934559084442661\n",
      "optimizer: adam\n",
      "units_2: 29\n",
      "grid_size_2: 4\n",
      "spline_order_2: 3\n",
      "units_3: 14\n",
      "grid_size_3: 4\n",
      "spline_order_3: 4\n",
      "units_4: 30\n",
      "grid_size_4: 7\n",
      "spline_order_4: 2\n",
      "Score: 0.0408504344522953\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 9\n",
      "grid_size_0: 5\n",
      "spline_order_0: 3\n",
      "units_1: 13\n",
      "grid_size_1: 7\n",
      "spline_order_1: 3\n",
      "learning_rate: 0.0003477023984973968\n",
      "optimizer: rmsprop\n",
      "units_2: 30\n",
      "grid_size_2: 3\n",
      "spline_order_2: 4\n",
      "units_3: 10\n",
      "grid_size_3: 5\n",
      "spline_order_3: 4\n",
      "units_4: 2\n",
      "grid_size_4: 3\n",
      "spline_order_4: 4\n",
      "Score: 0.04546918347477913\n",
      "\n",
      "Trial 47 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 28\n",
      "grid_size_0: 5\n",
      "spline_order_0: 2\n",
      "units_1: 25\n",
      "grid_size_1: 7\n",
      "spline_order_1: 2\n",
      "learning_rate: 0.0007776554202493605\n",
      "optimizer: adam\n",
      "units_2: 14\n",
      "grid_size_2: 6\n",
      "spline_order_2: 3\n",
      "units_3: 8\n",
      "grid_size_3: 6\n",
      "spline_order_3: 3\n",
      "units_4: 21\n",
      "grid_size_4: 6\n",
      "spline_order_4: 2\n",
      "Score: 0.06397140771150589\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 20\n",
      "grid_size_0: 4\n",
      "spline_order_0: 2\n",
      "units_1: 28\n",
      "grid_size_1: 3\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0002308841572663884\n",
      "optimizer: adam\n",
      "units_2: 7\n",
      "grid_size_2: 4\n",
      "spline_order_2: 4\n",
      "units_3: 8\n",
      "grid_size_3: 5\n",
      "spline_order_3: 3\n",
      "units_4: 14\n",
      "grid_size_4: 6\n",
      "spline_order_4: 3\n",
      "Score: 0.0777173638343811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gobba\\miniconda3\\envs\\kambinete\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:690: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 32 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0211 - mae: 0.0211 - mse: 0.0371 - rmse: 0.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.02077632211148739\n",
      "Test MSE: 0.033895332366228104\n",
      "Test MAE: 0.020776323974132538\n",
      "Test RMSE: 0.18410685658454895\n"
     ]
    }
   ],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(tf.keras.layers.Input(shape=self.input_shape))\n",
    "        \n",
    "        for i in range(hp.Int('num_layers', 2, 5)):\n",
    "            model.add(DenseKAN(\n",
    "                units=hp.Int('units_' + str(i), min_value=1, max_value=32, step=1),\n",
    "                grid_size=hp.Int('grid_size_' + str(i), 3, 7),\n",
    "                spline_order=hp.Int('spline_order_' + str(i), 2, 4)\n",
    "            ))\n",
    "        \n",
    "        model.add(DenseKAN(1))\n",
    "\n",
    "        learning_rate = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "        optimizer = hp.Choice('optimizer', ['adam', 'adagrad', 'rmsprop', 'adadelta'])\n",
    "        \n",
    "        if optimizer == 'adam':\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif optimizer == 'adagrad':\n",
    "            opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "        elif optimizer == 'rmsprop':\n",
    "            opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "        else:\n",
    "            opt = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "\n",
    "        model.compile(optimizer=opt,\n",
    "                      loss='mean_absolute_error',\n",
    "                      metrics=[\n",
    "                          tf.keras.metrics.MeanSquaredError(name='mse'),\n",
    "                          tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                          tf.keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "                      ])\n",
    "        return model\n",
    "\n",
    "# Assumo che x_train, y_train siano già definiti\n",
    "hypermodel = MyHyperModel(input_shape=(26,))\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "    directory=r\".\\modelli_salvati\",\n",
    "    project_name='retina_kan'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(x_train)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    train_indices = tf.convert_to_tensor(train_indices, dtype=tf.int32)\n",
    "    val_indices = tf.convert_to_tensor(val_indices, dtype=tf.int32)\n",
    "    \n",
    "    x_train_fold, x_val_fold = tf.gather(x_train, train_indices), tf.gather(x_train, val_indices)\n",
    "    y_train_fold, y_val_fold = tf.gather(y_train, train_indices), tf.gather(y_train, val_indices)\n",
    "\n",
    "    tuner.search(x_train_fold, y_train_fold,\n",
    "                 epochs=100,\n",
    "                 validation_data=(x_val_fold, y_val_fold),\n",
    "                 callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "tuner.results_summary()\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Valutazione del modello migliore sul set di test\n",
    "# Assumo che x_test, y_test siano già definiti\n",
    "test_loss, test_mse, test_mae, test_rmse = best_model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "# Salvataggio del modello migliore\n",
    "best_model.save('best_retina_kan_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers: 4\n",
      "units_0: 8\n",
      "grid_size_0: 3\n",
      "spline_order_0: 3\n",
      "units_1: 21\n",
      "grid_size_1: 4\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0050089061837515795\n",
      "optimizer: adam\n",
      "units_2: 32\n",
      "grid_size_2: 7\n",
      "spline_order_2: 2\n",
      "units_3: 8\n",
      "grid_size_3: 6\n",
      "spline_order_3: 2\n",
      "units_4: 11\n",
      "grid_size_4: 5\n",
      "spline_order_4: 2\n"
     ]
    }
   ],
   "source": [
    "# Ottieni i migliori iperparametri\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Ottieni e stampa i nomi e i valori dei parametri\n",
    "for param_name in best_hyperparameters.values.keys():\n",
    "    print(f\"{param_name}: {best_hyperparameters.get(param_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello 1\n",
      "num_layers: 4\n",
      "units_0: 8\n",
      "grid_size_0: 3\n",
      "spline_order_0: 3\n",
      "units_1: 21\n",
      "grid_size_1: 4\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0050089061837515795\n",
      "optimizer: adam\n",
      "units_2: 32\n",
      "grid_size_2: 7\n",
      "spline_order_2: 2\n",
      "units_3: 8\n",
      "grid_size_3: 6\n",
      "spline_order_3: 2\n",
      "units_4: 11\n",
      "grid_size_4: 5\n",
      "spline_order_4: 2\n",
      "\n",
      "\n",
      "Modello 2\n",
      "num_layers: 5\n",
      "units_0: 22\n",
      "grid_size_0: 5\n",
      "spline_order_0: 2\n",
      "units_1: 5\n",
      "grid_size_1: 4\n",
      "spline_order_1: 3\n",
      "learning_rate: 0.0003082442963419899\n",
      "optimizer: adam\n",
      "units_2: 24\n",
      "grid_size_2: 5\n",
      "spline_order_2: 3\n",
      "units_3: 27\n",
      "grid_size_3: 7\n",
      "spline_order_3: 4\n",
      "units_4: 13\n",
      "grid_size_4: 7\n",
      "spline_order_4: 2\n",
      "\n",
      "\n",
      "Modello 3\n",
      "num_layers: 4\n",
      "units_0: 4\n",
      "grid_size_0: 3\n",
      "spline_order_0: 4\n",
      "units_1: 23\n",
      "grid_size_1: 5\n",
      "spline_order_1: 3\n",
      "learning_rate: 0.0015324287478969592\n",
      "optimizer: adam\n",
      "units_2: 26\n",
      "grid_size_2: 4\n",
      "spline_order_2: 4\n",
      "units_3: 14\n",
      "grid_size_3: 4\n",
      "spline_order_3: 2\n",
      "units_4: 16\n",
      "grid_size_4: 3\n",
      "spline_order_4: 4\n",
      "\n",
      "\n",
      "Modello 4\n",
      "num_layers: 4\n",
      "units_0: 22\n",
      "grid_size_0: 4\n",
      "spline_order_0: 4\n",
      "units_1: 23\n",
      "grid_size_1: 3\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0019505034249811953\n",
      "optimizer: adam\n",
      "units_2: 8\n",
      "grid_size_2: 7\n",
      "spline_order_2: 3\n",
      "units_3: 15\n",
      "grid_size_3: 7\n",
      "spline_order_3: 2\n",
      "units_4: 21\n",
      "grid_size_4: 5\n",
      "spline_order_4: 2\n",
      "\n",
      "\n",
      "Modello 5\n",
      "num_layers: 2\n",
      "units_0: 26\n",
      "grid_size_0: 6\n",
      "spline_order_0: 3\n",
      "units_1: 8\n",
      "grid_size_1: 7\n",
      "spline_order_1: 2\n",
      "learning_rate: 0.0014487708708113137\n",
      "optimizer: adam\n",
      "units_2: 8\n",
      "grid_size_2: 7\n",
      "spline_order_2: 2\n",
      "units_3: 23\n",
      "grid_size_3: 4\n",
      "spline_order_3: 4\n",
      "units_4: 16\n",
      "grid_size_4: 3\n",
      "spline_order_4: 2\n",
      "\n",
      "\n",
      "Modello 6\n",
      "num_layers: 5\n",
      "units_0: 6\n",
      "grid_size_0: 6\n",
      "spline_order_0: 4\n",
      "units_1: 17\n",
      "grid_size_1: 6\n",
      "spline_order_1: 2\n",
      "learning_rate: 0.0004059999358516054\n",
      "optimizer: adam\n",
      "units_2: 16\n",
      "grid_size_2: 5\n",
      "spline_order_2: 3\n",
      "units_3: 12\n",
      "grid_size_3: 7\n",
      "spline_order_3: 3\n",
      "units_4: 5\n",
      "grid_size_4: 5\n",
      "spline_order_4: 3\n",
      "\n",
      "\n",
      "Modello 7\n",
      "num_layers: 5\n",
      "units_0: 9\n",
      "grid_size_0: 7\n",
      "spline_order_0: 4\n",
      "units_1: 3\n",
      "grid_size_1: 3\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.00010934559084442661\n",
      "optimizer: adam\n",
      "units_2: 29\n",
      "grid_size_2: 4\n",
      "spline_order_2: 3\n",
      "units_3: 14\n",
      "grid_size_3: 4\n",
      "spline_order_3: 4\n",
      "units_4: 30\n",
      "grid_size_4: 7\n",
      "spline_order_4: 2\n",
      "\n",
      "\n",
      "Modello 8\n",
      "num_layers: 4\n",
      "units_0: 9\n",
      "grid_size_0: 5\n",
      "spline_order_0: 3\n",
      "units_1: 13\n",
      "grid_size_1: 7\n",
      "spline_order_1: 3\n",
      "learning_rate: 0.0003477023984973968\n",
      "optimizer: rmsprop\n",
      "units_2: 30\n",
      "grid_size_2: 3\n",
      "spline_order_2: 4\n",
      "units_3: 10\n",
      "grid_size_3: 5\n",
      "spline_order_3: 4\n",
      "units_4: 2\n",
      "grid_size_4: 3\n",
      "spline_order_4: 4\n",
      "\n",
      "\n",
      "Modello 9\n",
      "num_layers: 2\n",
      "units_0: 28\n",
      "grid_size_0: 5\n",
      "spline_order_0: 2\n",
      "units_1: 25\n",
      "grid_size_1: 7\n",
      "spline_order_1: 2\n",
      "learning_rate: 0.0007776554202493605\n",
      "optimizer: adam\n",
      "units_2: 14\n",
      "grid_size_2: 6\n",
      "spline_order_2: 3\n",
      "units_3: 8\n",
      "grid_size_3: 6\n",
      "spline_order_3: 3\n",
      "units_4: 21\n",
      "grid_size_4: 6\n",
      "spline_order_4: 2\n",
      "\n",
      "\n",
      "Modello 10\n",
      "num_layers: 4\n",
      "units_0: 20\n",
      "grid_size_0: 4\n",
      "spline_order_0: 2\n",
      "units_1: 28\n",
      "grid_size_1: 3\n",
      "spline_order_1: 4\n",
      "learning_rate: 0.0002308841572663884\n",
      "optimizer: adam\n",
      "units_2: 7\n",
      "grid_size_2: 4\n",
      "spline_order_2: 4\n",
      "units_3: 8\n",
      "grid_size_3: 5\n",
      "spline_order_3: 3\n",
      "units_4: 14\n",
      "grid_size_4: 6\n",
      "spline_order_4: 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ottieni i migliori iperparametri per i primi 10 modelli\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=10)\n",
    "\n",
    "# Per ogni set di iperparametri\n",
    "for i, hyperparameters in enumerate(best_hyperparameters):\n",
    "    print(f\"Modello {i+1}\")\n",
    "    # Ottieni e stampa i nomi e i valori dei parametri\n",
    "    for param_name in hyperparameters.values.keys():\n",
    "        print(f\"{param_name}: {hyperparameters.get(param_name)}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
